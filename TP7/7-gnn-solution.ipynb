{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD212: Graph mining\n",
    "\n",
    "## Lab 7: Graph neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn to classify nodes using graph neural networks.\n",
    "\n",
    "We use [DGL](https://www.dgl.ai) (deep graph library), which relies on pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dgl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl import function as fn\n",
    "from dgl.nn import SAGEConv\n",
    "from scipy import sparse\n",
    "from sknetwork.classification import DiffusionClassifier\n",
    "from sknetwork.data import load_netset\n",
    "from sknetwork.embedding import Spectral\n",
    "from sknetwork.utils import directed2undirected\n",
    "from torch import nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the following datasets (see the [NetSet](https://netset.telecom-paris.fr/) collection for details):\n",
    "* Cora (directed graph + bipartite graph)\n",
    "* WikiVitals (directed graph + bipartite graph)\n",
    "\n",
    "Both datasets are graphs with node features (given by the bipartite graph) and ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing files...\n",
      "Done.\n",
      "Parsing files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "cora = load_netset(\"cora\")\n",
    "wikivitals = load_netset(\"wikivitals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cora\n",
    "# dataset = wikivitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = dataset.adjacency\n",
    "biadjacency = dataset.biadjacency\n",
    "labels = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use undirected graphs\n",
    "adjacency = directed2undirected(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Wikivitals, use spectral embedding of the bipartite graph as features\n",
    "\n",
    "if dataset.meta.name.startswith(\"Wikivitals\"):\n",
    "    spectral = Spectral(50)\n",
    "    features = spectral.fit_transform(biadjacency)\n",
    "else:\n",
    "    features = biadjacency.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_val(n_samples, test_ratio=0.1, val_ratio=0.1, seed=None):\n",
    "    \"\"\"Split the samples into train / test / validation sets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train: np.ndarray\n",
    "        Boolean mask\n",
    "    test: np.ndarray\n",
    "        Boolean mask\n",
    "    validation: np.ndarray\n",
    "        Boolean mask\n",
    "    \"\"\"\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # test\n",
    "    index = np.random.choice(\n",
    "        n_samples, int(np.ceil(n_samples * test_ratio)), replace=False\n",
    "    )\n",
    "    test = np.zeros(n_samples, dtype=bool)\n",
    "    test[index] = 1\n",
    "\n",
    "    # validation\n",
    "    index = np.random.choice(\n",
    "        np.argwhere(~test).ravel(), int(np.ceil(n_samples * val_ratio)), replace=False\n",
    "    )\n",
    "    val = np.zeros(n_samples, dtype=bool)\n",
    "    val[index] = 1\n",
    "\n",
    "    # train\n",
    "    train = np.ones(n_samples, dtype=bool)\n",
    "    train[test] = 0\n",
    "    train[val] = 0\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = split_train_test_val(len(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph and tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DGL, the graph is represented as an object, the features and labels as tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph as an object\n",
    "graph = dgl.from_scipy(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dgl.heterograph.DGLGraph"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels as tensors\n",
    "features = torch.Tensor(features)\n",
    "labels = torch.Tensor(labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks as tensors\n",
    "train = torch.Tensor(train).bool()\n",
    "test = torch.Tensor(test).bool()\n",
    "val = torch.Tensor(val).bool()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a simple graph neural network without hidden layer. The output layer is of type [GraphSAGE](https://docs.dgl.ai/generated/dgl.nn.pytorch.conv.SAGEConv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv = SAGEConv(dim_input, dim_output, aggregator_type=\"mean\")\n",
    "\n",
    "    def forward(self, graph, features):\n",
    "        output = self.conv(graph, features)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Train the model on Cora and get accuracy.\n",
    "* Compare with the same model trained on an empty graph.\n",
    "* Add a hidden layer with ReLu activation function (e.g., dimension = 20) and retrain the model. \n",
    "* Compare with a classifier based on heat diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model, features, labels):\n",
    "    \"\"\"Init the GNN with appropriate dimensions.\"\"\"\n",
    "    dim_input = features.shape[1]\n",
    "    dim_output = len(labels.unique())\n",
    "    return model(dim_input, dim_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(gnn, graph, features, labels, test=test):\n",
    "    \"\"\"Evaluate the model in terms of accuracy.\"\"\"\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        output = gnn(graph, features)\n",
    "        labels_pred = torch.max(output, dim=1)[1]\n",
    "        score = np.mean(np.array(labels[test]) == np.array(labels_pred[test]))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    gnn,\n",
    "    graph,\n",
    "    features,\n",
    "    labels,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    n_epochs=100,\n",
    "    lr=0.01,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"Train the GNN.\"\"\"\n",
    "    optimizer = torch.optim.Adam(gnn.parameters(), lr=lr)\n",
    "\n",
    "    gnn.train()\n",
    "    scores = []\n",
    "\n",
    "    for t in range(n_epochs):\n",
    "\n",
    "        # forward\n",
    "        output = gnn(graph, features)\n",
    "        logp = nn.functional.log_softmax(output, 1)\n",
    "        loss = nn.functional.nll_loss(logp[train], labels[train])\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # evaluation\n",
    "        score = eval_model(gnn, graph, features, labels, val)\n",
    "        scores.append(score)\n",
    "\n",
    "        if verbose and t % 10 == 0:\n",
    "            print(\n",
    "                \"Epoch {:02d} | Loss {:.3f} | Accuracy {:.3f}\".format(\n",
    "                    t, loss.item(), score\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 1.938 | Accuracy 0.387\n",
      "Epoch 10 | Loss 0.585 | Accuracy 0.827\n",
      "Epoch 20 | Loss 0.247 | Accuracy 0.852\n",
      "Epoch 30 | Loss 0.135 | Accuracy 0.856\n",
      "Epoch 40 | Loss 0.087 | Accuracy 0.860\n",
      "Epoch 50 | Loss 0.063 | Accuracy 0.852\n",
      "Epoch 60 | Loss 0.050 | Accuracy 0.841\n",
      "Epoch 70 | Loss 0.041 | Accuracy 0.834\n",
      "Epoch 80 | Loss 0.035 | Accuracy 0.834\n",
      "Epoch 90 | Loss 0.030 | Accuracy 0.834\n"
     ]
    }
   ],
   "source": [
    "train_model(gnn, graph, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450184501845018"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_graph = dgl.from_scipy(sparse.csr_matrix(adjacency.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 1.984 | Accuracy 0.347\n",
      "Epoch 10 | Loss 0.601 | Accuracy 0.823\n",
      "Epoch 20 | Loss 0.252 | Accuracy 0.852\n",
      "Epoch 30 | Loss 0.137 | Accuracy 0.852\n",
      "Epoch 40 | Loss 0.088 | Accuracy 0.845\n",
      "Epoch 50 | Loss 0.064 | Accuracy 0.841\n",
      "Epoch 60 | Loss 0.050 | Accuracy 0.841\n",
      "Epoch 70 | Loss 0.042 | Accuracy 0.834\n",
      "Epoch 80 | Loss 0.035 | Accuracy 0.827\n",
      "Epoch 90 | Loss 0.031 | Accuracy 0.827\n"
     ]
    }
   ],
   "source": [
    "train_model(gnn, graph, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6568265682656826"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, empty_graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output, dim_hidden=20):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(dim_input, dim_hidden, \"mean\")\n",
    "        self.conv2 = SAGEConv(dim_hidden, dim_output, \"mean\")\n",
    "\n",
    "    def forward(self, graph, features):\n",
    "        h = self.conv1(graph, features)\n",
    "        h = F.relu(h)\n",
    "        output = self.conv2(graph, h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 1.982 | Accuracy 0.454\n",
      "Epoch 10 | Loss 0.163 | Accuracy 0.863\n",
      "Epoch 20 | Loss 0.025 | Accuracy 0.867\n",
      "Epoch 30 | Loss 0.007 | Accuracy 0.867\n",
      "Epoch 40 | Loss 0.003 | Accuracy 0.867\n",
      "Epoch 50 | Loss 0.002 | Accuracy 0.863\n",
      "Epoch 60 | Loss 0.001 | Accuracy 0.867\n",
      "Epoch 70 | Loss 0.001 | Accuracy 0.863\n",
      "Epoch 80 | Loss 0.001 | Accuracy 0.863\n",
      "Epoch 90 | Loss 0.001 | Accuracy 0.863\n"
     ]
    }
   ],
   "source": [
    "train_model(gnn, graph, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8597785977859779"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison with heat diffusion\n",
    "y_true = dataset.labels\n",
    "y_train = y_true.copy()\n",
    "y_train[test | val] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = DiffusionClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = algo.fit_predict(biadjacency, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859778597785978"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred[test] == y_true[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = algo.fit_predict(adjacency, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8597785977859779"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred[test] == y_true[test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own GNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now build your own GNN. We start with a simple graph convolution layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.layer = nn.Linear(dim_input, dim_output)\n",
    "\n",
    "    def forward(self, graph, signal):\n",
    "        with graph.local_scope():\n",
    "            # message passing\n",
    "            graph.ndata[\"node\"] = signal\n",
    "            graph.update_all(\n",
    "                fn.copy_u(\"node\", \"message\"), fn.mean(\"message\", \"average\")\n",
    "            )\n",
    "            h = graph.ndata[\"average\"]\n",
    "            return self.layer(h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the message passing is based on the diffusion:\n",
    "$$U\\mapsto PU$$ where $P$ is the transition matrix of the random walk."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Build a GNN with two layers based on this graph convolution layer.\n",
    "* Train this GNN and compare the results with the previous one.\n",
    "* Add the input signal of each node, so that the message passing becomes:\n",
    "$$\n",
    "U\\mapsto (I + P)U\n",
    "$$\n",
    "* Retrain the GNN and observe the results.\n",
    "* Retrain the same GNN without message passing in the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden=20):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GraphConvLayer(n_input, n_hidden)\n",
    "        self.conv2 = GraphConvLayer(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, graph, features):\n",
    "        h = self.conv1(graph, features)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 1.958 | Accuracy 0.310\n",
      "Epoch 10 | Loss 1.227 | Accuracy 0.697\n",
      "Epoch 20 | Loss 0.519 | Accuracy 0.860\n",
      "Epoch 30 | Loss 0.283 | Accuracy 0.875\n",
      "Epoch 40 | Loss 0.201 | Accuracy 0.867\n",
      "Epoch 50 | Loss 0.153 | Accuracy 0.841\n",
      "Epoch 60 | Loss 0.122 | Accuracy 0.834\n",
      "Epoch 70 | Loss 0.100 | Accuracy 0.830\n",
      "Epoch 80 | Loss 0.083 | Accuracy 0.838\n",
      "Epoch 90 | Loss 0.070 | Accuracy 0.838\n"
     ]
    }
   ],
   "source": [
    "gnn = init_model(GNN, features, labels)\n",
    "train_model(gnn, graph, features, labels, train, val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302583025830258"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.layer = nn.Linear(dim_input, dim_output)\n",
    "\n",
    "    def forward(self, graph, signal):\n",
    "        with graph.local_scope():\n",
    "            # message passing\n",
    "            graph.ndata[\"node\"] = signal\n",
    "            graph.update_all(\n",
    "                fn.copy_u(\"node\", \"message\"), fn.mean(\"message\", \"average\")\n",
    "            )\n",
    "            h = graph.ndata[\"average\"]\n",
    "            return self.layer(h + signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden=20):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GraphConvLayer(n_input, n_hidden)\n",
    "        self.conv2 = GraphConvLayer(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, graph, features):\n",
    "        h = self.conv1(graph, features)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 1.937 | Accuracy 0.483\n",
      "Epoch 10 | Loss 0.307 | Accuracy 0.871\n",
      "Epoch 20 | Loss 0.132 | Accuracy 0.875\n",
      "Epoch 30 | Loss 0.068 | Accuracy 0.867\n",
      "Epoch 40 | Loss 0.042 | Accuracy 0.860\n",
      "Epoch 50 | Loss 0.029 | Accuracy 0.863\n",
      "Epoch 60 | Loss 0.022 | Accuracy 0.867\n",
      "Epoch 70 | Loss 0.017 | Accuracy 0.860\n",
      "Epoch 80 | Loss 0.015 | Accuracy 0.860\n",
      "Epoch 90 | Loss 0.013 | Accuracy 0.860\n"
     ]
    }
   ],
   "source": [
    "gnn = init_model(GNN, features, labels)\n",
    "train_model(gnn, graph, features, labels, train, val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8708487084870848"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.layer = nn.Linear(dim_input, dim_output)\n",
    "\n",
    "    def forward(self, features):\n",
    "        output = self.layer(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden=20):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = ConvLayer(n_input, n_hidden)\n",
    "        self.conv2 = GraphConvLayer(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, graph, features):\n",
    "        h = self.conv1(features)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 1.912 | Accuracy 0.328\n",
      "Epoch 10 | Loss 0.550 | Accuracy 0.856\n",
      "Epoch 20 | Loss 0.153 | Accuracy 0.875\n",
      "Epoch 30 | Loss 0.060 | Accuracy 0.889\n",
      "Epoch 40 | Loss 0.031 | Accuracy 0.886\n",
      "Epoch 50 | Loss 0.019 | Accuracy 0.878\n",
      "Epoch 60 | Loss 0.014 | Accuracy 0.875\n",
      "Epoch 70 | Loss 0.011 | Accuracy 0.875\n",
      "Epoch 80 | Loss 0.009 | Accuracy 0.878\n",
      "Epoch 90 | Loss 0.008 | Accuracy 0.878\n"
     ]
    }
   ],
   "source": [
    "train_model(gnn, graph, features, labels, train, val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819188191881919"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat diffusion as a GNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node classification by heat diffusion can be seen as a GNN without training, using a one-hot encoding of labels. Features are ignored."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Build a special GNN whose output corresponds to one step of heat diffusion in the graph.\n",
    "* Use this GNN to classify nodes by heat diffusion, with temperature centering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.utils import get_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_one_hot = get_membership(labels).toarray()\n",
    "labels_one_hot = torch.Tensor(labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Diffusion, self).__init__()\n",
    "\n",
    "    def forward(self, graph, features, mask):\n",
    "        \"\"\"Mask is a boolean tensor giving the training set.\"\"\"\n",
    "        with graph.local_scope():\n",
    "            h_node = features\n",
    "            # diffusion\n",
    "            graph.ndata[\"node\"] = h_node\n",
    "            graph.update_all(\n",
    "                fn.copy_src(\"node\", \"message\"), fn.mean(\"message\", \"neighbor\")\n",
    "            )\n",
    "            h_neighbor = graph.ndata[\"neighbor\"]\n",
    "            # seed nodes\n",
    "            h_neighbor[mask] = h_node[mask]\n",
    "            return h_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = Diffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dgl.function' has no attribute 'copy_src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m temperatures[\u001b[38;5;241m~\u001b[39mtrain] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[1;32m----> 6\u001b[0m     temperatures \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# temperature centering\u001b[39;00m\n\u001b[0;32m      9\u001b[0m temperatures \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m temperatures\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\willf\\.conda\\envs\\sd212\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willf\\.conda\\envs\\sd212\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 12\u001b[0m, in \u001b[0;36mDiffusion.forward\u001b[1;34m(self, graph, features, mask)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# diffusion\u001b[39;00m\n\u001b[0;32m     10\u001b[0m graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m h_node\n\u001b[0;32m     11\u001b[0m graph\u001b[38;5;241m.\u001b[39mupdate_all(\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_src\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m), fn\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneighbor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m h_neighbor \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneighbor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# seed nodes\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dgl.function' has no attribute 'copy_src'"
     ]
    }
   ],
   "source": [
    "n_iter = 20\n",
    "\n",
    "temperatures = labels_one_hot\n",
    "temperatures[~train] = 0\n",
    "for t in range(n_iter):\n",
    "    temperatures = diffusion(graph, temperatures, train)\n",
    "\n",
    "# temperature centering\n",
    "temperatures -= temperatures.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = np.argmax(temperatures.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(labels.numpy()[test] == labels_pred[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison with scikit-network\n",
    "from sknetwork.classification import DiffusionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = DiffusionClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[~train] = -1\n",
    "labels = labels.numpy()\n",
    "labels_true = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = algo.fit_predict(adjacency, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(labels_true[test] == labels_pred[test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
